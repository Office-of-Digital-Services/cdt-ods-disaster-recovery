{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"California Digital Disaster Recovery Center (DDRC)","text":"<p>This website provides technical documentation for the DDRC application from the California Department of Technology (CDT).</p> <p>DDRC is a web application that enables free vital records replacement for survivors of the 2025 Los Angeles County fires and other recent natural disasters in California. It is open-source software that is designed, developed, and maintained by Compiler LLC on behalf of CDT.</p>"},{"location":"#supported-vital-records-requests","title":"Supported vital records requests","text":"<p>The DDRC app supports the following vital records requests:</p> Vital Record Type Status Launch Birth Certificate Live 08/2025 Marriage Certificate Live 09/2025 Death Certificate Live 10/2025"},{"location":"#technical-and-security-details","title":"Technical and security details","text":"<p>DDRC is a Django 5 web application. The application uses Login.gov\u2019s Identity Assurance Level 2 (IAL2) via the California Identity Gateway to verify a person has an address in a disaster-affected zip code.</p> <p>Running the application locally is possible with Docker and Docker Compose.</p> <p>The application communicates with the California Identity Gateway via redirects, over the public internet. See all the system interconnections.</p>"},{"location":"#infrastructure","title":"Infrastructure","text":"<p>The DDRC application is deployed to Microsoft Azure. Traffic is encrypted between the user and the application, as well as between the application and external systems.</p> <p>The network is managed by CDT, who provide a firewall and distributed denial-of-service (DDoS) protection.</p> <p>You can find more technical details on our infrastructure page.</p>"},{"location":"#data-storage","title":"Data storage","text":"<p>The DDRC application minimizes the information exchanged between systems. The following information is temporarily stored in a secure database:</p> <ul> <li>The user\u2019s attestation and information required to submit a vital records request</li> </ul> <p>Sensitive user information exists in the following places:</p> <ul> <li>To qualify for free vital records replacement, users need to provide personal information to Login.gov</li> <li>Users need to provide their attestation and vital record information to submit a vital records request</li> </ul> <p>Learn more about the security/privacy practices of our integration partners:</p> <ul> <li>Login.gov</li> <li>CDT privacy policy</li> </ul> <p>DDRC collects analytics on usage, without any identifying information. You can find more details on our analytics page.</p>"},{"location":"#practices","title":"Practices","text":"<p>Dependabot immediately notifies the team of vulnerabilities in application dependencies.</p> <p>Upon doing new major integrations, features, or architectural changes, the DDRC team has a penetration test performed by a third party to ensure the security of the system.</p> <p>All code changes are reviewed by at least one other member of the engineering team, which is enforced through branch protections.</p>"},{"location":"concepts/","title":"Vital Records Request","text":"<p>A description of a vital records request lifecycle and its participants.</p>"},{"location":"concepts/#birth","title":"Birth","text":"<p>A description of a birth request.</p>"},{"location":"concepts/#marriage","title":"Marriage","text":"<p>A description of a marriage request.</p>"},{"location":"guides/development/","title":"Development","text":"<p>This project is configured to use VS Code devcontainers to provide a platform-agnostic, standardized development environment.</p>"},{"location":"guides/development/#prerequisites","title":"Prerequisites","text":"Expand for prerequisites <p>This section describes the tooling you need to have installed and configured on your development machine before continuing.</p>"},{"location":"guides/development/#git","title":"Git","text":"<p>Git is an open source version control system that we use in <code>DDRC</code> to track changes to the codebase over time. Many operating systems come with Git already installed. Check if you have Git installed in a terminal with the following command:</p> <pre><code>git --version\n</code></pre> <p>If git is installed, the output should look similar to:</p> <pre><code>$ git --version\ngit version 2.39.5\n</code></pre> <p>If Git is not installed, head to the Git downloads page to get an installer for your operating system.</p>"},{"location":"guides/development/#docker-and-docker-compose","title":"Docker and Docker Compose","text":"<p>Docker and Docker Compose (or just Compose) are key tools that allow for running the various services required for <code>DDRC</code>.</p> <p>Confirm if you already have Docker installed, in a terminal:</p> <pre><code>docker --version\n</code></pre> <p>If Docker is installed, the output should look similar to:</p> <pre><code>$ docker --version\nDocker version 27.4.0, build bde2b89\n</code></pre> <p>And similarly to check if Compose is installed:</p> <pre><code>docker compose version\n</code></pre> <p>When Compose is installed, output will look similar to:</p> <pre><code>$ docker compose version\nDocker Compose version v2.31.0\n</code></pre> <p>There are different ways to acquire this software depending on your operating system. Although the simplest approach for Windows and MacOS users is to install Docker Desktop, we recommend following the steps below.</p>"},{"location":"guides/development/#windows","title":"Windows","text":"<p>It is possible to run Docker and Compose on Windows without installing Docker Desktop. This involves using the Windows Subsystem for Linux v2 (WSL2), where Docker is configured to run.</p> <p>This article walks through this procedure in more detail: How to run docker on Windows without Docker Desktop.</p>"},{"location":"guides/development/#macos","title":"MacOS","text":"<p>With MacOS and Homebrew, installing Docker and Compose are as simple as:</p> <pre><code>brew install docker docker-compose colima\n</code></pre> <p>Once the install completes, start <code>colima</code> (an open source container runtime):</p> <pre><code>brew services start colima\n</code></pre>"},{"location":"guides/development/#linux","title":"Linux","text":"<p>Docker CE (also known as Docker Engine) is how to run Docker and Compose on Linux. Docker provides an installation guide for Docker CE.</p>"},{"location":"guides/development/#vs-code-and-dev-containers-extension","title":"VS Code and Dev Containers extension","text":"<p>VS Code is an open source Integrated Development Environment (IDE) from Microsoft. Check if you already have it installed:</p> <pre><code>code -v\n</code></pre> <p>If installed, output should look similar to:</p> <pre><code>$ code -v\n1.95.3\nf1a4fb101478ce6ec82fe9627c43efbf9e98c813\nx64\n</code></pre> <p>Otherwise, download VS Code for your operating system.</p> <p>Once installed, open VS Code and enter <code>Ctrl</code>/<code>Cmd</code> + <code>P</code> to open the VS Code Quick Open pane. Then enter:</p> <pre><code>ext install ms-vscode-remote.remote-containers\n</code></pre> <p><code>ms-vscode-remote.remote-containers</code> is the Extension ID of the Dev Containers extension from Microsoft.</p>"},{"location":"guides/development/#get-the-project-code","title":"Get the project code","text":"<p>Use Git to clone the repository to your local machine:</p> <pre><code>git clone https://github.com/Office-of-Digital-Services/cdt-ods-disaster-recovery.git\n</code></pre> <p>Then change into the <code>cdt-ods-disaster-recovery</code> directory and create an environment file from the sample:</p> <pre><code>cd cdt-ods-disaster-recovery\ncp .env.sample .env\n</code></pre> <p>Feel free to inspect the environment file, but leave the defaults for now.</p> <p>Then build the application and devcontainer Docker images:</p> <pre><code>bin/build.sh\n</code></pre>"},{"location":"guides/development/#open-the-project-in-a-vs-code-devcontainer","title":"Open the project in a VS Code devcontainer","text":"<p>Still in your terminal, enter the following command to open the project in VS Code:</p> <pre><code>code .\n</code></pre> <p>Once the project is loaded in VS Code, you should see a notification pop-up asking to reopen the project in a devcontainer.</p> <p>If you don\u2019t see this notification, or if it was dismissed, use the VS Code Quick Open pane with <code>Ctrl</code>/<code>Cmd</code> + <code>P</code> and enter:</p> <pre><code>&gt; Dev Containers: Rebuild and Reopen in Container\n</code></pre> <p>The VS Code window will reload into the devcontainer.</p> <p>Once loaded, hit <code>F5</code> to start the application in debug mode. The application is now running on <code>http://localhost:8000</code>.</p>"},{"location":"guides/hotfix/","title":"Making a hotfix release","text":"<p>This list outlines the manual steps needed to make a hotfix release of the <code>DDRC</code> app.</p> <p>If <code>main</code> contains in-progress work that is not yet ready for a release but a simple code fix is needed in production, a separate process to test the changes before deploying to production must be undertaken. This is called a hotfix release. Typically, a hotfix release involves a simple code change that can be quickly implemented, in contrast to a rollback release, which generally requires more complex code changes which take more time to implement.</p>"},{"location":"guides/hotfix/#0-create-a-temporary-hotfix-branch-from-the-latest-release-tag","title":"0. Create a temporary hotfix branch from the latest release tag","text":"<pre><code>git checkout -b &lt;hotfix-branch&gt; &lt;release-tag&gt;\n</code></pre> <p>Replace <code>&lt;hotfix-branch&gt;</code> with the hotfix branch name and <code>&lt;release-tag&gt;</code> with the latest release tag.</p>"},{"location":"guides/hotfix/#1-fix-whatever-issue-is-wrong-using-the-hotfix-branch","title":"1. Fix whatever issue is wrong using the hotfix branch","text":"<p>Commit the code changes that fix the issue that prompted the hotfix.</p>"},{"location":"guides/hotfix/#2-tag-the-head-of-the-hotfix-branch-with-a-release-tag","title":"2. Tag the HEAD of the hotfix branch with a release tag","text":"<pre><code>git tag -a YYYY.0M.R\n</code></pre> <p>Git will open your default text editor and prompt you for the tag annotation. For the tag annotation, use the release tag version and close the text editor.</p>"},{"location":"guides/hotfix/#3-push-the-tag-to-github-to-kick-off-the-hotfix","title":"3. Push the tag to GitHub to kick off the hotfix","text":"<pre><code>git push origin YYYY.0M.R\n</code></pre>"},{"location":"guides/hotfix/#4-generate-release-notes","title":"4. Generate release notes","text":"<p>Edit release notes with additional context, images, animations, etc. as-needed and link to the Release process issue.</p>"},{"location":"guides/hotfix/#5-merge-into-main-for-the-next-release","title":"5. Merge into <code>main</code> for the next release","text":"<p>Create a PR to merge the changes from the hotfix branch into <code>main</code> for the next release.</p>"},{"location":"guides/infrastructure/","title":"Making infrastructure changes via Terraform","text":"<p>Since the DDRC app is deployed into a Microsoft Azure account provided by the California Department of Technology (CDT)\u2019s Office of Enterprise Technology (OET) team, as a first step, you\u2019ll need to request access from them to the <code>CDT Digital CA</code> directory so you can get into the Azure portal, and to the <code>CalEnterprise</code> directory so you can access Azure DevOps. You can refer to Azure\u2019s documentation for switching directories.</p>"},{"location":"guides/infrastructure/#setup-for-local-development","title":"Setup for local development","text":"<ol> <li> <p>Get access to the Azure account through the DevSecOps team.</p> <p>Secured Azure resources</p> <p>To run Terraform from your local machine, you must grant your IP address access to the secured Azure resources. Both the Azure Storage Account, where the Terraform state is stored, and the Azure Key Vaults are protected by firewalls that restrict access. Follow these steps to add your current public IP address to their firewall rules.</p> <p>Azure Storage Account</p> <ol> <li>In the Azure Portal, navigate to the production Storage Account</li> <li>From the left-hand menu, select <code>Security+Networking</code>, then click on <code>Networking</code></li> <li>Under <code>Resource settings: Virtual networks, IP addresses, and exceptions</code>, click on <code>Manage</code> and add your IP address to the <code>IPv4 Addresses</code> list</li> </ol> <p>Azure Key Vault</p> <ol> <li>In the Azure Portal, navigate to the Key Vault</li> <li>From the left-hand menu, select <code>Settings</code>, then click on <code>Networking</code></li> <li>Under <code>Firewall</code>, add your IP address to the <code>IP address or CIDR</code> list</li> </ol> <p>Note that the DevOps <code>deploy</code> pipeline also gets its IP address and gives itself access to these resources.</p> </li> <li> <p>Install dependencies:</p> <ul> <li>Azure CLI</li> <li>Terraform - see exact version in <code>deploy.yml</code></li> </ul> </li> <li> <p>Authenticate using the Azure CLI.</p> <pre><code>az login\n</code></pre> </li> <li> <p>Outside the dev container, navigate to the <code>terraform/</code> directory.</p> </li> <li> <p>Initialize Terraform. You can also use this script later to switch between environments.</p> <pre><code>./init.sh &lt;env&gt;\n</code></pre> </li> <li> <p>Create a local <code>terraform.tfvars</code> file (ignored by git) from the sample; fill in the <code>*_OBJECT_ID</code> variables with values from the Azure Pipeline definition.</p> </li> </ol>"},{"location":"guides/infrastructure/#development-process","title":"Development process","text":"<p>When configuration changes to infrastructure resources are needed, they should be made to the resource definitions in Terraform and submitted via pull request.</p> <ol> <li>Make changes to Terraform files.</li> <li> <p>Preview the changes, as necessary.</p> <pre><code>terraform plan\n</code></pre> </li> <li> <p>Submit the changes via pull request.</p> </li> </ol> <p>Azure tags</p> <p>For Azure resources, you need to ignore changes to tags, since they are automatically created by an Azure Policy managed by CDT.</p> <pre><code>lifecycle {\n    ignore_changes = [tags]\n}\n</code></pre>"},{"location":"guides/infrastructure/#azure-environment-setup","title":"Azure environment setup","text":"<p>These steps were followed when setting up our Azure deployment for the first time:</p> <ul> <li>CDT team creates the resources that they own</li> <li><code>terraform apply</code></li> <li>Set up Slack notifications by creating a Slack email for the <code>#shared-cdt-ddrc-notify</code> channel, then setting it as a Secret in the Key Vault named <code>slack-ddrc-notify-email</code></li> <li>Set required Container App configuration by setting values in Key Vault (the mapping is defined in app_web.tf and modules.tf)</li> </ul> <p>This is not a complete step-by-step guide; more a list of things to remember.</p>"},{"location":"guides/release/","title":"Making a regular release","text":"<p>This list outlines the manual steps needed to make a new release of the <code>DDRC</code> app.</p> <p>A release is made by pushing an annotated tag. The name of the tag must use the version number format mentioned below. This kicks off a deployment to the production environment and creates a GitHub release. The version number for the app and the release will be the tag\u2019s name. More details on the deployment steps can be found in the Deploy Workflow.</p> <p>The list of releases can be found on the repository Releases page on GitHub.</p>"},{"location":"guides/release/#0-decide-on-the-new-version-number","title":"0. Decide on the new version number","text":"<p>A new release implies a new version.</p> <p><code>DDRC</code> uses the CalVer versioning scheme, where version numbers look like: <code>YYYY.0M.R</code></p> <ul> <li><code>YYYY</code> is the 4-digit year of the release; e.g. <code>2021</code>, <code>2022</code></li> <li><code>0M</code> is the 2-digit, 0-padded month of the release; e.g. <code>02</code> is February, <code>12</code>   is December.</li> <li><code>R</code> is the 1-based release counter for the given year and month;   e.g. <code>1</code> for the first release of the month, <code>2</code> for the second, and so on.</li> </ul> <p>Version numbers for release candidates append <code>-rcR</code>, where <code>R</code> is the 1-based release counter for the anticipated release. For example, the first release candidate for the <code>2024.01.1</code> release would be <code>2024.01.1-rc1</code>.</p>"},{"location":"guides/release/#1-create-a-release-candidate-tag-on-main-and-push-it","title":"1. Create a release candidate tag on <code>main</code> and push it","text":"<pre><code>git fetch\ngit checkout main\ngit reset --hard origin/main\ngit tag -a YYYY.0M.R-rcR\n</code></pre> <p>Git will open your default text editor and prompt you for the tag annotation. For the tag annotation, use the release candidate version. Finally, after closing the text editor:</p> <pre><code>git push origin YYYY.0M.R-rcR\n</code></pre> <p>This builds a new package and deploys to the Azure test environments. No GitHub release is created for release candidates.</p>"},{"location":"guides/release/#2-create-a-release-tag-on-main-and-push-it","title":"2. Create a release tag on <code>main</code> and push it","text":"<pre><code>git fetch\ngit checkout main\ngit reset --hard origin/main\ngit tag -a YYYY.0M.R\n</code></pre> <p>Git will open your default text editor and prompt you for the tag annotation. For the tag annotation, use the title of the Release process issue that kicked off the release. Finally, after closing the text editor:</p> <pre><code>git push origin YYYY.0M.R\n</code></pre> <p>This builds the package and deploys to the Azure production environments. A GitHub release is created.</p>"},{"location":"guides/release/#3-generate-release-notes","title":"3. Generate release notes","text":"<p>Edit release notes with additional context, images, animations, etc. as-needed and link to the Release process issue.</p>"},{"location":"guides/rollback/","title":"Making a rollback release","text":"<p>This list outlines the manual steps needed to make a rollback of the <code>DDRC</code> app.</p> <p>If a change is deployed to the app that makes it fail to start, making a rollback will deploy the app to a known working state again.</p>"},{"location":"guides/rollback/#0-create-a-release-tag-on-the-commit-associated-with-the-last-known-good-release-tag","title":"0. Create a release tag on the commit associated with the last known good release tag","text":"<pre><code>git tag -a YYYY.0M.R &lt;commit-hash&gt;\n</code></pre> <p>Replace <code>YYYY.0M.R</code> with the rollback version and <code>&lt;commit-hash&gt;</code> with the hash of the commit associated with the last known good release tag. Git will open your default text editor and prompt you for the tag annotation. For the tag annotation, use the version of the release tag for the rollback and close the text editor.</p>"},{"location":"guides/rollback/#1-push-the-tag-to-github-to-kick-off-the-rollback","title":"1. Push the tag to GitHub to kick off the rollback","text":"<pre><code>git push origin YYYY.0M.R\n</code></pre>"},{"location":"guides/rollback/#2-generate-release-notes","title":"2. Generate release notes","text":"<p>Edit release notes with additional context, images, animations, etc. as-needed and link to the Release process issue.</p>"},{"location":"reference/analytics/","title":"Analytics","text":"<p>A description of what (and why) is being tracked.</p> <p>Technical details of how analytics are implemented.</p>"},{"location":"reference/application-logic/","title":"Application logic","text":"<p>This page describes how DDRC defines user flows through the following high-level phases:</p> <ol> <li>Identity proofing</li> <li>Eligibility verification</li> <li>Vital records request</li> </ol> <pre><code>flowchart LR\n    start((Start))\n    identity[Identity proofing]\n    eligibility[Eligibility verification]\n    enrollment[Vital records request]\n    complete((End))\n    style complete stroke-width:2px\n\n    start --&gt; identity\n    identity --&gt; eligibility\n    eligibility --&gt; enrollment\n    enrollment --&gt; complete</code></pre> <p>The structure of the source code in <code>cdt-ods-disaster-recovery/</code> generally follows from these phases:</p> <ul> <li><code>web/core/</code> implements shared logic, models, and hooks for <code>django-cdt-identity/</code></li> <li><code>web/vital_records/</code> implements a request for   vital records</li> <li><code>web/vital_records/tasks/</code> implements async tasks run by a task queue</li> </ul> <p><code>core</code> and <code>vital_records</code> are standalone Django apps registered in Django\u2019s settings.</p> <p>Furthermore, the source code in <code>django-cdt-identity/</code> implements identity proofing in:</p> <ul> <li><code>cdt_identity/</code> implements identity proofing and   claims verification with the California Department of Technology\u2019s Identity Gateway</li> </ul>"},{"location":"reference/application-logic/#django-request-pipeline","title":"Django request pipeline","text":"<p>Each request to the DDRC app is ultimately a Django request and goes through the Django HTTP request pipeline.</p> <p>DDRC uses middleware to pre- and post-process requests for (view) access control, and session configuration.</p> <p>Key supporting files</p> <p><code>web/core/middleware.py</code></p> <p>In general, the flow of a Django request looks like:</p> <pre><code>flowchart LR\n    user((User))\n    style user stroke-width:2px\n\n    pre_middleware[Request middleware]\n    view_middleware[View-specific middleware]\n    context[Context processors]\n    view[View function]\n    post_middleware[Response middleware]\n\n    user -- Request --&gt; pre_middleware\n    pre_middleware -- Request --&gt; view_middleware\n    view_middleware -- Request --&gt; context\n    context -- Request --&gt; view\n    view -- Response --&gt; post_middleware\n    post_middleware -- Response --&gt; user</code></pre>"},{"location":"reference/application-logic/#identity-proofing","title":"Identity proofing","text":"<p>In this phase, DDRC takes the user through an OpenID Connect (OIDC) flow as a Client (the Relying Party or RP) of the CDT Identity Gateway (the Identity Provider or IDP), via Login.gov.</p> <p>The CDT Identity Gateway transforms PII from Login.gov into anonymized boolean claims that are later used in eligibility verification.</p> <p>Entrypoint</p> <p><code>cdt-ods-disaster-recovery/web/vital_records/views/common.py</code></p> <p>Key supporting files</p> <p><code>django-cdt-identity/cdt_identity/client.py</code></p> <p><code>django-cdt-identity/cdt_identity/hooks.py</code></p> <pre><code>flowchart LR\n    session[(session)]\n\n    start((Start))\n\n    ddrc[DDRC app]\n    idg[[\"`CDT\n    Identity Gateway`\"]]\n    logingov[[Login.gov]]\n    claims((Claims received))\n\n    next&gt;\"`_Eligibility\n    verification_`\"]\n    style next stroke-width:2px\n\n    start -- \"1: Clicks login button\" --&gt; ddrc\n    %% invisible links help with diagram layout\n    start ~~~ session\n\n    ddrc -- \"2: OIDC authorize_redirect\" --&gt; idg\n\n    idg &lt;-. \"3: PII exchange\" .-&gt; logingov\n    idg -- \"4: OIDC token authorization\" --&gt; claims\n\n    claims -- \"5: continue\" --&gt; next\n    claims -. update .-o session</code></pre>"},{"location":"reference/application-logic/#eligibility-verification","title":"Eligibility verification","text":"<p>In this phase, DDRC verifies the user\u2019s claims by using claims previously stored in the user\u2019s session during Identity proofing</p> <p>Entrypoint</p> <p><code>cdt-ods-disaster-recovery/web/vital_records/views/common.py</code></p> <p>Key supporting files</p> <p><code>django-cdt-identity/cdt_identity/views.py</code></p> <pre><code>flowchart LR\n    session[(session)]\n\n    start((\"`Previous\n    phase`\"))\n    style start stroke-dasharray: 5 5\n\n    claims[Session claims check]\n    eligible{Eligible?}\n\n    next&gt;\"`_Vital records request_`\"]\n    style next stroke-width:2px\n\n    stop{{Stop}}\n\n    start -- Claims validation --&gt; claims\n    session -.-o claims\n    claims --&gt; eligible\n\n    eligible -- Yes --&gt; next\n    eligible -- No --&gt; stop\n    eligible -. update .-o session</code></pre>"},{"location":"reference/application-logic/#vital-records-request","title":"Vital records request","text":"<p>In this final phase, the user fills out a series of forms to submit an order for a vital records request and the DDRC application generates a PDF of the vital records request and emails it to the California Department of Public Health (CDPH).</p>"},{"location":"reference/application-logic/#order-records","title":"Order records","text":""},{"location":"reference/application-logic/#birth","title":"Birth","text":"<p>The user fills out the following forms:</p> <ul> <li>Name on birth certificate</li> <li>County of birth</li> <li>Date of birth</li> <li>Name of parents</li> <li>Order information</li> </ul> <p>Entrypoint</p> <p><code>cdt-ods-disaster-recovery/web/vital_records/views/common.py</code></p> <p>Supporting views</p> <p><code>cdt-ods-disaster-recovery/web/vital_records/views/birth.py</code></p>"},{"location":"reference/application-logic/#marriage","title":"Marriage","text":"<p>The user fills out the following forms:</p> <ul> <li>Name of persons on marriage record</li> <li>County of marriage</li> <li>Date of marriage</li> <li>Order information</li> </ul> <p>Entrypoint</p> <p><code>cdt-ods-disaster-recovery/web/vital_records/views/common.py</code></p> <p>Supporting views</p> <p><code>cdt-ods-disaster-recovery/web/vital_records/views/marriage.py</code></p>"},{"location":"reference/application-logic/#submit-records","title":"Submit records","text":"<p>The DDRC application generates a PDF of the vital records request and emails it to CDPH.</p> <p>Async tasks</p> <p><code>cdt-ods-disaster-recovery/web/vital_records/tasks/package.py</code></p> <p><code>cdt-ods-disaster-recovery/web/vital_records/tasks/email.py</code></p> <pre><code>sequenceDiagram\nautonumber\n\n    actor user as User\n    participant ddrc as DDRC app\n    participant package as package task\n    participant email as email task\n    participant cdph as CDPH\n\nuser-&gt;&gt;ddrc: submit order for vital records request\n    activate user\nddrc--&gt;&gt;user: confirmation of order submission\n    deactivate user\nddrc-&gt;&gt;package: mark request as ready for processing\n    activate ddrc\npackage-&gt;&gt;email: create vital records request PDF application\n    activate package\n    deactivate ddrc\nemail-&gt;&gt;cdph: email vital records request PDF application\n    deactivate package\n    activate email\nemail-&gt;&gt;user: email confirmation of vital records request PDF application submittal\n    deactivate email</code></pre>"},{"location":"reference/commits-branches-merging/","title":"Commits, branches, and merging","text":""},{"location":"reference/commits-branches-merging/#commits","title":"Commits","text":"<p>This project enforces the Conventional Commits style for commit message formatting:</p> <pre><code>&lt;type&gt;[(optional-scope)]: &lt;description&gt;\n\n[optional body]\n</code></pre> <p>Where <code>&lt;type&gt;</code> indicates the nature of the commit, one of a list of possible values:</p> <ul> <li><code>build</code> - related to the build or compile process</li> <li><code>chore</code> - administrative tasks, cleanups, dev environment</li> <li><code>ci</code> - related to automated builds/tests etc.</li> <li><code>docs</code> - updates to the documentation</li> <li><code>feat</code> - new code, features, or interfaces</li> <li><code>fix</code> - bug fixes</li> <li><code>perf</code> - performance improvements</li> <li><code>refactor</code> - non-breaking logic refactors</li> <li><code>revert</code> - undo a prior change</li> <li><code>style</code> - code style and formatting</li> <li><code>test</code> - having to do with testing of any kind</li> </ul> <p>E.g.</p> <pre><code>git commit -m \"feat(vital-records/urls): add path for start\"\n</code></pre>"},{"location":"reference/commits-branches-merging/#branches","title":"Branches","text":"<p>The default GitHub branch is <code>main</code>. All new feature work should be in the form of Pull Requests (PR) that target <code>main</code> as their base.</p> <p>In addition to <code>main</code>, the repository has a few other long-lived branches:</p> <ul> <li><code>gh-pages</code> hosts the compiled documentation, and is always forced-pushed by the   docs build process</li> <li><code>python-coverage-comment-action-data</code> acts as a persistent data store for the Python Coverage Comment GitHub Action   and is created and managed by it</li> </ul>"},{"location":"reference/commits-branches-merging/#protection-rules","title":"Protection rules","text":"<p>Branch protection rules are in place on <code>main</code> to:</p> <ul> <li>Prevent branch deletion</li> <li>Restrict force-pushing, where appropriate</li> <li>Require passing status checks before merging into the target branch is allowed</li> </ul>"},{"location":"reference/commits-branches-merging/#pr-branches","title":"PR branches","text":"<p>PR branches are typically named with a conventional type prefix, a slash <code>/</code>, and then descriptor in <code>lower-dashed-case</code>:</p> <pre><code>&lt;type&gt;/&lt;lower-dashed-descriptor&gt;\n</code></pre> <p>E.g.</p> <pre><code>git checkout -b feat/flow-multi-select\n</code></pre> <p>and</p> <pre><code>git checkout -b refactor/flow-model\n</code></pre> <p>PR branches are deleted once their PR is merged.</p>"},{"location":"reference/commits-branches-merging/#merging","title":"Merging","text":"<p>Merging of PRs should be done using the merge commit strategy. The PR author should utilize <code>git rebase -i</code> to ensure their PR commit history is clean, logical, and free of typos.</p> <p>When merging a PR into <code>main</code>, it is customary to format the merge commit message like:</p> <pre><code>Title of PR (#number)\n</code></pre> <p>instead of the default:</p> <pre><code>Merge pull request #number from source-repo/source-branch\n</code></pre>"},{"location":"reference/infrastructure/","title":"Infrastructure","text":"<p>The infrastructure is configured as code via Terraform, for various reasons, and is deployed into a Microsoft Azure account provided by the California Department of Technology (CDT)\u2019s Office of Enterprise Technology (OET) team.</p> <p>The Azure portal is where you can view the infrastructure resources for DDRC. Azure DevOps is where our infrastructure pipeline is run to build and deploy those infrastructure resources.</p>"},{"location":"reference/infrastructure/#environments","title":"Environments","text":"<p>Within the <code>CDT Digital CA</code> directory, there are two Subscriptions, with Resource Groups under each. However, only one subscription is currently being used for DDRC.</p> <p>Each of our environments corresponds to a single Resource Group and Terraform Workspace.</p> Environment Subscription Resource Group Workspace Dev <code>CDT/ODI Production</code> <code>RG-CDT-PUB-VIP-DDRC-D-001</code> <code>dev</code> Test <code>CDT/ODI Production</code> <code>RG-CDT-PUB-VIP-DDRC-T-001</code> <code>test</code> Prod <code>CDT/ODI Production</code> <code>RG-CDT-PUB-VIP-DDRC-P-001</code> <code>default</code> <p>All resources in these Resource Groups should be reflected in Terraform in this repository. The exceptions are:</p> <ul> <li>Secrets, such as values under Key Vault. <code>prevent_destroy</code> is used on these Resources.</li> <li>Things managed by DevSecOps</li> </ul>"},{"location":"reference/infrastructure/#ownership","title":"Ownership","text":"<p>The following things in Azure are managed by CDT\u2019s OET DevSecOps team:</p> <ul> <li>Subcriptions</li> <li>Resource Groups</li> <li>Networking</li> <li>Front Door<ul> <li>Web Application Firewall (WAF) </li> <li>Distributed denial-of-service (DDoS) protection </li> </ul> </li> <li>IAM</li> <li>Service connections</li> </ul> <p>You\u2019ll see these referenced in Terraform as data sources, meaning they are managed outside of Terraform.</p>"},{"location":"reference/infrastructure/#architecture","title":"Architecture","text":"<p>These diagrams show a high-level view of the architecture per environment, including some external systems such as error monitoring.</p>"},{"location":"reference/infrastructure/#ddrc-application","title":"DDRC application","text":"<pre><code>flowchart LR\n    internet[Public internet]\n    frontdoor[Front Door]\n    django[Django application]\n    interconnections[Other system interconnections]\n\n    internet --&gt; Cloudflare\n    Cloudflare --&gt; frontdoor\n    django &lt;--&gt; interconnections\n\n    subgraph Azure\n        frontdoor --&gt; NGINX\n\n        subgraph App Service\n            subgraph Custom container\n                direction TB\n                NGINX --&gt; django\n            end\n        end\n    end</code></pre> <p>Front Door also includes the Web Application Firewall (WAF) and handles TLS termination. Front Door is managed by the DevSecOps team.</p>"},{"location":"reference/infrastructure/#system-interconnections","title":"System interconnections","text":"<pre><code>flowchart LR\n    ddrc[DDRC application]\n    style ddrc stroke-width:5px\n    rider((User's browser))\n    idg[Identity Gateway]\n    task_queue[Task queue]\n    app_db[(PostgreSQL)]\n    cookies[(Cookies)]\n    monitoring[Azure Monitor]\n\n    ddrc --&gt;|Errors| monitoring\n\n    rider --&gt; ddrc\n    rider --&gt;|Credentials and identity proofing| Login.gov\n    rider --&gt;|Session| cookies\n\n    ddrc --&gt; idg\n    ddrc &lt;--&gt; app_db\n\n    subgraph \"Database and task queue\"\n    task_queue &lt;--&gt; app_db\n    end\n\n    idg --&gt; Login.gov\n    Login.gov --&gt;|User attributes| idg\n    idg --&gt;|User attributes| ddrc</code></pre>"},{"location":"reference/infrastructure/#naming-conventions","title":"Naming conventions","text":"<p>The DevSecOps team sets the following naming convention for Resources:</p> <p><code>&lt;!-- markdownlint-disable-line MD040 --&gt; &lt;&lt;Resource Type&gt;&gt;-&lt;&lt;Department&gt;&gt;-&lt;&lt;Public/Private&gt;&gt;-&lt;&lt;Project Category&gt;&gt;-&lt;&lt;Project Name&gt;&gt;-&lt;&lt;Region&gt;&gt;&lt;&lt;OS Type&gt;&gt;-&lt;&lt;Environment&gt;&gt;-&lt;&lt;Sequence Number&gt;&gt;</code></p>"},{"location":"reference/infrastructure/#sample-names","title":"Sample Names","text":"<ul> <li><code>RG-CDT-PUB-VIP-BNSCN-E-D-001</code></li> <li><code>ASP-CDT-PUB-VIP-BNSCN-EL-P-001</code></li> <li><code>AS-CDT-PUB-VIP-BNSCN-EL-D-001</code></li> </ul>"},{"location":"reference/infrastructure/#resource-types","title":"Resource Types","text":"<p>Use the following shorthand for conveying the Resource Type as part of the Resource Name:</p> Resource Convention App Service <code>AS</code> App Service Plan <code>ASP</code> Virtual Network <code>VNET</code> Resource Group <code>RG</code> Virtual Machine <code>VM</code> Database <code>DB</code> Subnet <code>SNET</code> Front Door <code>FD</code>"},{"location":"reference/terraform/","title":"Terraform","text":"<p>This document provides a detailed reference for the Terraform configuration that defines the project\u2019s infrastructure. Terraform is used to implement the principle of Infrastructure as Code (IaC), which allows us to manage and provision our infrastructure through code and configuration files.</p> <p>The core Terraform configuration is located in the <code>/terraform</code> directory.</p> <p>The primary goal of this configuration is to create a secure, repeatable, and modular infrastructure on Microsoft Azure. The Terraform Azure Provider defines the necessary resource blocks to enable this configuration in Terraform.</p>"},{"location":"reference/terraform/#workspaces","title":"Workspaces","text":"<p>The project uses Terraform Workspaces to manage and deploy to multiple environments from the same codebase. Each workspace corresponds to a distinct environment and has its own state file, which prevents environments from interfering with each other.</p> <p>The workspaces are:</p> <ul> <li><code>dev</code>: Corresponds to the <code>dev</code> environment.</li> <li><code>test</code>: Corresponds to the <code>test</code> environment.</li> <li><code>default</code>: Corresponds to the <code>prod</code> environment.</li> </ul> <p>While each workspace is distinct with its own state file, all 3 state files are stored in the <code>prod</code> environment.</p> <p>The selection of the workspace is automated in the Azure DevOps pipeline. The <code>terraform/pipeline/workspace.py</code> script inspects the Git branch or tag that triggered the pipeline to determine which workspace to use. For example, a pull request to <code>main</code> will deploy to the <code>dev</code> environment, while a release tag will deploy to <code>test</code> or <code>prod</code>.</p> <p>For more details on each Azure environment, see the Environments section in the Infrastructure reference.</p>"},{"location":"reference/terraform/#directory-structure","title":"Directory structure","text":"<p>The <code>/terraform</code> directory is organized to separate concerns between the root configuration, reusable modules, and Azure DevOps pipeline logic.</p> <pre><code>/terraform\n\u251c\u2500\u2500 alerts.tf\n\u251c\u2500\u2500 azure-pipelines.yml\n\u251c\u2500\u2500 main.tf\n\u251c\u2500\u2500 modules.tf\n\u251c\u2500\u2500 security.tf\n\u251c\u2500\u2500 variables.tf\n\u251c\u2500\u2500 modules/\n\u2502   \u251c\u2500\u2500 application/\n\u2502   \u251c\u2500\u2500 database/\n\u2502   \u251c\u2500\u2500 email/\n\u2502   \u251c\u2500\u2500 key_vault/\n\u2502   \u251c\u2500\u2500 monitoring/\n\u2502   \u251c\u2500\u2500 network/\n\u2502   \u2514\u2500\u2500 storage/\n\u251c\u2500\u2500 pipeline/\n\u2502   \u251c\u2500\u2500 deploy.yml\n\u2502   \u251c\u2500\u2500 tags.py\n\u2502   \u2514\u2500\u2500 workspace.py\n\u2514\u2500\u2500 secrets/\n    \u251c\u2500\u2500 file.sh\n    \u251c\u2500\u2500 read.sh\n    \u2514\u2500\u2500 value.sh\n</code></pre>"},{"location":"reference/terraform/#root-files","title":"Root files","text":"<ul> <li><code>main.tf</code>: The entrypoint for the root module. It configures the Azure provider and backend state storage.</li> <li><code>variables.tf</code>: Defines input variables for the root module, such as subscription and object IDs.</li> <li><code>modules.tf</code>: The central wiring file that instantiates all the core modules from the <code>modules/</code> directory and connects their inputs and outputs.</li> <li><code>security.tf</code>: Contains centralized security configurations, such as Network Security Group (NSG) rules and Key Vault access policies that span across multiple modules.</li> <li><code>alerts.tf</code>: Defines monitoring alerts, such as the Application Insights error alert.</li> </ul>"},{"location":"reference/terraform/#modules","title":"<code>modules/</code>","text":"<p>This directory contains reusable, self-contained modules for different parts of the infrastructure. Each subdirectory is a separate Terraform module.</p>"},{"location":"reference/terraform/#pipeline","title":"<code>pipeline/</code>","text":"<p>Contains the definitions for the Azure DevOps pipeline that automates <code>terraform plan</code> and <code>terraform apply</code>.</p>"},{"location":"reference/terraform/#secrets","title":"<code>secrets/</code>","text":"<p>Includes helper scripts for manually reading and writing secrets to Azure Key Vault.</p>"},{"location":"reference/terraform/#root-modules","title":"Root modules","text":"<p>The <code>.tf</code> files in the root of the <code>/terraform</code> directory define the core configuration and orchestrate the modules.</p>"},{"location":"reference/terraform/#maintf","title":"<code>main.tf</code>","text":"<p>Source</p> <p><code>terraform/main.tf</code></p> <p>This file is the primary entrypoint for the Terraform configuration. It is responsible for:</p> <ul> <li>Provider Configuration: It declares the required providers, <code>azurerm</code> and <code>random</code>, and their versions.</li> <li>Backend Configuration: It configures the <code>azurerm</code> backend, which tells Terraform to store its state file in an Azure Storage Account. This is critical for a team environment to ensure that the state is shared and locked to prevent concurrent modifications.</li> <li>Core Data Lookups: It uses data sources to fetch information about the Azure environment at runtime, such as the current client configuration (<code>azurerm_client_config</code>) and the main resource group (<code>azurerm_resource_group</code>).</li> </ul>"},{"location":"reference/terraform/#modulestf","title":"<code>modules.tf</code>","text":"<p>Source</p> <p><code>terraform/modules.tf</code></p> <p>This file acts as the central nervous system for the infrastructure, connecting all the individual modules defined in the <code>/terraform/modules</code> directory.</p> <ul> <li>Orchestration: It instantiates each core module (<code>network</code>, <code>monitoring</code>, <code>database</code>, etc.).</li> <li>Wiring: It passes the outputs from one module as inputs to another. This creates a dependency graph and ensures resources are created in the correct order. For example, the network module\u2019s subnet IDs are passed to the application and database modules.</li> <li>Consistent Naming: It defines a <code>locals</code> block that establishes a consistent naming convention for resources across all modules, based on the environment.</li> </ul> <p>Here is an example of how <code>modules.tf</code> wires the <code>monitoring</code> and <code>network</code> modules together:</p> <pre><code>module \"monitoring\" {\n  source                        = \"./modules/monitoring\"\n  # ... other variables\n}\n\nmodule \"network\" {\n  source                     = \"./modules/network\"\n  log_analytics_workspace_id = module.monitoring.log_analytics_workspace_id\n  # ... other variables\n}\n</code></pre>"},{"location":"reference/terraform/#securitytf","title":"<code>security.tf</code>","text":"<p>Source</p> <p><code>terraform/security.tf</code></p> <p>This file centralizes security-related configurations that span across multiple modules. This separation of concerns makes it easier to manage and audit security settings. Its responsibilities include:</p> <ul> <li>Key Vault Access Policies: It creates <code>azurerm_key_vault_access_policy</code> resources to grant the managed identities of the application\u2019s container apps (<code>web</code>, <code>worker</code>, <code>functions</code>) the necessary permissions to read secrets from Key Vault.</li> <li>Network Security Group (NSG) Rules: It defines the specific <code>azurerm_network_security_rule</code> resources that allow or deny traffic between the different subnets. For example, it contains rules to allow the application subnet to communicate with the database subnet on the correct port.</li> </ul>"},{"location":"reference/terraform/#alertstf","title":"<code>alerts.tf</code>","text":"<p>Source</p> <p><code>terraform/alerts.tf</code></p> <p>This file is dedicated to defining monitoring alerts for the application. It creates an <code>azurerm_monitor_scheduled_query_rules_alert_v2</code> resource that:</p> <ul> <li>Runs a query against Application Insights logs on a schedule (e.g., every 5 minutes).</li> <li>The query checks for exceptions or high-severity traces.</li> <li>If the query returns any results, it triggers an alert that notifies the team via the action group configured in the <code>monitoring</code> module.</li> </ul>"},{"location":"reference/terraform/#core-modules-terraformmodules","title":"Core modules (<code>terraform/modules/*</code>)","text":"<p>The <code>terraform/modules/</code> directory contains a set of reusable modules, each responsible for a specific piece of the infrastructure. This modular approach makes the configuration easier to manage and reason about.</p> <p>The modules below are reflected in more-or-less \u201cdependency\u201d order, e.g. we need the network to exist before we can create a database, and that has to exist before we can create the apps.</p>"},{"location":"reference/terraform/#network","title":"<code>network</code>","text":"<p>Source</p> <p><code>terraform/modules/network/</code></p> <p>Creates the foundational networking resources for the application.</p> <p>Key resources:</p> <ul> <li><code>azurerm_virtual_network</code>: The main VNet for the environment.</li> <li><code>azurerm_subnet</code>: Creates multiple subnets for different components (e.g., <code>public</code>, <code>worker</code>, <code>db</code>, <code>key_vault</code>).</li> <li><code>azurerm_nat_gateway</code>: Provides outbound internet access for resources in the private subnets.</li> <li><code>azurerm_network_security_group</code>: Defines NSGs to control traffic flow.</li> </ul>"},{"location":"reference/terraform/#monitoring","title":"<code>monitoring</code>","text":"<p>Source</p> <p><code>terraform/modules/monitoring/</code></p> <p>Sets up the shared monitoring, logging, and alerting infrastructure.</p> <p>Key resources:</p> <ul> <li><code>azurerm_log_analytics_workspace</code>: The central workspace for collecting logs and metrics.</li> <li><code>azurerm_application_insights</code>: The Application Performance Management (APM) service for the application.</li> <li><code>azurerm_monitor_action_group</code>: Defines a group of actions (like sending an email or calling a webhook) to take when an alert is triggered.</li> </ul>"},{"location":"reference/terraform/#key_vault","title":"<code>key_vault</code>","text":"<p>Source</p> <p><code>terraform/modules/key_vault/</code></p> <p>Deploys a secure and private Azure Key Vault for managing secrets.</p> <p>Key resources:</p> <ul> <li><code>azurerm_key_vault</code>: The Key Vault instance.</li> <li><code>azurerm_private_endpoint</code>: Exposes the Key Vault on a private IP address within the VNet.</li> <li><code>azurerm_key_vault_access_policy</code>: Base policies for administrative groups.</li> </ul>"},{"location":"reference/terraform/#database","title":"<code>database</code>","text":"<p>Source</p> <p><code>terraform/modules/database/</code></p> <p>Deploys the PostgreSQL database for the application.</p> <p>Key resources:</p> <ul> <li><code>azurerm_postgresql_flexible_server</code>: The managed PostgreSQL server.</li> <li><code>azurerm_private_endpoint</code>: Exposes the database on a private IP address within the VNet.</li> <li><code>azurerm_key_vault_secret</code>: Creates a secret in Key Vault for the generated database password.</li> </ul>"},{"location":"reference/terraform/#storage","title":"<code>storage</code>","text":"<p>Source</p> <p><code>terraform/modules/storage/</code></p> <p>Creates the Azure Storage Account and file shares required by the application.</p> <p>Key resources:</p> <ul> <li><code>azurerm_storage_account</code>: The main storage account.</li> <li><code>azurerm_storage_share</code>: Creates file shares for <code>config</code> and <code>requests</code>.</li> <li><code>azurerm_private_endpoint</code>: Exposes the storage account\u2019s blob and file services on private IP addresses.</li> </ul>"},{"location":"reference/terraform/#email","title":"<code>email</code>","text":"<p>Source</p> <p><code>terraform/modules/email/</code></p> <p>Configures the Azure Communication Service for sending emails.</p> <p>Key resources:</p> <ul> <li><code>azurerm_communication_service</code>: The core communication service.</li> <li><code>azurerm_email_communication_service</code>: The email-specific service.</li> <li><code>azurerm_email_communication_service_domain</code>: Configures the sending domain (<code>AzureManaged</code> for non-prod, <code>CustomerManaged</code> for prod).</li> </ul>"},{"location":"reference/terraform/#application","title":"<code>application</code>","text":"<p>Source</p> <p><code>terraform/modules/application/</code></p> <p>Deploys the application components. This is the most complex module, bringing together many of the resources from other modules.</p> <p>Key resources:</p> <ul> <li><code>azurerm_container_app_environment</code>: Creates two environments, one for the public-facing <code>web</code> app and another for the internal <code>worker</code> and <code>functions</code> apps.</li> <li><code>azurerm_container_app</code>: Deploys the <code>web</code>, <code>worker</code>, and <code>functions</code> container apps.</li> <li><code>azurerm_user_assigned_identity</code>: Creates managed identities for each container app to enable secure access to other Azure resources (like Key Vault).</li> <li><code>azurerm_key_vault_secret</code>: Creates application-specific secrets in Key Vault.</li> </ul>"},{"location":"reference/terraform/#managing-secrets","title":"Managing secrets","text":"<p>A robust secret management strategy is in place to handle sensitive information like passwords, API keys, and connection strings.</p>"},{"location":"reference/terraform/#azure-key-vault","title":"Azure Key Vault","text":"<p>The primary storage for all secrets is Azure Key Vault. This provides a secure, centralized repository with access control and auditing.</p>"},{"location":"reference/terraform/#terraform-and-key-vault","title":"Terraform and Key Vault","text":"<ul> <li>Terraform is configured to create secrets in Key Vault (e.g., generated database passwords).</li> <li>The application container apps are configured to read secrets directly from Key Vault using their managed identities. The <code>secrets</code> blocks in the <code>azurerm_container_app</code> resources and the associated <code>azurerm_key_vault_access_policy</code> resources manage this.</li> </ul>"},{"location":"reference/terraform/#manual-secret-management","title":"Manual secret management","text":"<p>For secrets that are not generated by Terraform (e.g., third-party API keys), the <code>terraform/secrets/</code> directory contains helper scripts:</p> <ul> <li><code>value.sh</code>: Sets a secret from a string value.</li> <li><code>file.sh</code>: Sets a secret from the contents of a file.</li> </ul>"},{"location":"reference/terraform/#local-development","title":"Local development","text":"<p>For local development, the <code>terraform.tfvars</code> file is used to provide secrets and other variables to Terraform. This file is explicitly ignored by Git (via <code>.gitignore</code>) to prevent accidental check-in of sensitive information. A <code>terraform.tfvars.sample</code> file is provided as a template.</p> <p>This approach ensures that secrets are not hard-coded in the codebase and are securely managed throughout the development and deployment lifecycle.</p>"},{"location":"reference/terraform/#infrastructure-pipeline","title":"Infrastructure pipeline","text":"<p>The pipeline is triggered by PRs against the <code>main</code> branch and by the GitHub Actions <code>deploy</code> workflow. The key characteristics of the pipeline are:</p>"},{"location":"reference/terraform/#terraform-plan","title":"<code>terraform plan</code>","text":"<p>For pull requests targeting the <code>main</code> branch, the pipeline runs a <code>terraform plan</code> to show a preview of the changes. This allows for a review of the potential impact before any changes are applied.</p>"},{"location":"reference/terraform/#terraform-apply","title":"<code>terraform apply</code>","text":"<p>The <code>terraform apply</code> command is run when:</p> <ul> <li>A pull request is merged into the <code>main</code> branch (deploying to the <code>dev</code> environment).</li> <li>A release candidate tag (e.g., <code>2025.10.1-rc1</code>) is pushed (deploying to the <code>test</code> environment).</li> <li>A release tag (e.g., <code>2025.10.1</code>) is pushed (deploying to the <code>prod</code> environment).</li> </ul>"},{"location":"reference/terraform/#modular-pipeline","title":"Modular pipeline","text":"<p>The core deployment logic is encapsulated in the <code>terraform/pipeline/deploy.yml</code> template, which is called by the main pipeline. This template handles installing Terraform, setting up authentication, and running the Terraform commands.</p>"},{"location":"reference/terraform/#dynamic-configuration","title":"Dynamic configuration","text":"<ul> <li>The <code>terraform/pipeline/workspace.py</code> script dynamically determines the correct Terraform workspace (<code>dev</code>, <code>test</code>, or <code>default</code>) to use based on the source branch or tag.</li> <li>The <code>terraform/pipeline/tags.py</code> script determines the container image tag to be deployed.</li> </ul> <p>While the primary CI/CD automation for this project is done through GitHub Actions, we use an Azure Pipeline for a couple of reasons:</p> <ul> <li>Easier authentication with the Azure API using a service connnection</li> <li>Log output is hidden, avoiding accidentally leaking secrets</li> </ul>"}]}